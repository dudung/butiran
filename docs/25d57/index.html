<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>fi3271 plan for 2024-2 | butiran</title>
<link rel=stylesheet href=/butiran/css/main.min.5d949e138e137f26bbbc6fbe151c3e39ca49a674bd5c6f0f3a9ff79176ee1043.css integrity="sha256-XZSeE44Tfya7vG++FRw+OcpJpnS9XG8POp/3kXbuEEM=" crossorigin=anonymous><script src=/butiran/js/main.23cd0c7d837263b9eaeb96ee2d9ccfa2969daa3fa00fa1c1fe8701a9b87251a1.js integrity="sha256-I80MfYNyY7nq65buLZzPopadqj+gD6HB/ocBqbhyUaE=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css></head><body><header><link rel=stylesheet href='/butiran/css/header.css?v=1764500270'><h1>butiran</h1><nav><ul><li><a href=/butiran/>Home</a></li></ul></nav></header><main><head><link rel=stylesheet href='/butiran/css/notes.css?v=1764500270'></head><div class=note-container><h1 class=note-title>fi3271 plan for 2024-2</h1><div class=info-after-title><ul class=authors-container><li class=author><a href=https://dudung.github.io/butiran/authors/viridi/>Sparisoma Viridi</a></li><li class=author><a href=https://dudung.github.io/butiran/authors/muttaqien/>Fahdzi Muttaqien</a></li></ul><div class=date-reading-time-edit><time datetime="2025-04-20T04:00:40 07:00">20 Apr 2025</time>
&#183;
3 mins read</div></div><div class=note-content><p>FI3271 Data Analysis with Machine Learning is a 3-hours course given in about 15-16 weeks. It is a part of
<a href=https://six.itb.ac.id/pub/kur2024/102 target=_blank rel="nofollow noopener noreferrer"><span>2024 curriculum <i class="fa fa-external-link" style=font-size:14px></i>
</span></a>.</p><h2 id=topics>topics</h2><ol><li>Computational thinking and algorithm design</li><li>Concepts in machine learning: supervised and unsupervised learning</li><li>Probability distributions and their applications</li><li>Linear models for regression and classification</li><li>Sampling methods and their role in data analysis</li><li>Artificial neural networks: structure and training</li><li>Gaussian process regression for atomic force field modeling</li><li>Genetic algorithms and evolutionary computation</li><li>Bayesian optimization and its applications</li></ol><h2 id=learning-outcome>learning outcome</h2><ol><li>Understand and explain the basic concepts of computational thinking</li><li>Design algorithms to solve problems involving physical systems and data</li><li>Apply machine learning techniques to analyze data from physical systems</li><li>Present scientific findings clearly in both written reports and oral presentations</li><li>Collaborate effectively in teams and work independently when needed</li></ol><h2 id=conducted-plan-fm>conducted plan (fm)</h2><link rel=stylesheet href="/butiran/css/table-0.css?v=1764500267"><div class=table-0><table><thead><tr><th style=text-align:center>Week</th><th style=text-align:left>Topic ↓ Subtopic</th></tr></thead><tbody><tr><td style=text-align:center> </td><td style=text-align:left><strong>Computational thinking and algorithm design</strong></td></tr><tr><td style=text-align:center>01.1</td><td style=text-align:left>Concept of computational thinking</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Abstraction and decomposition</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Pattern recognition</td></tr><tr><td style=text-align:center>01.2</td><td style=text-align:left>Algorithmic thinking</td></tr><tr><td style=text-align:center> </td><td style=text-align:left><strong>Sampling methods and their role in data analysis</strong></td></tr><tr><td style=text-align:center>02.1</td><td style=text-align:left>Data mining</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Data preprocessing</td></tr><tr><td style=text-align:center> </td><td style=text-align:left><strong>Linear models for regression and classification</strong></td></tr><tr><td style=text-align:center>02.2</td><td style=text-align:left>Linear regression</td></tr><tr><td style=text-align:center>04.1</td><td style=text-align:left>Classification with Support Vector Machine (SVM)</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Quiz</td></tr><tr><td style=text-align:center>04.2</td><td style=text-align:left>Support Vector Machine kernels</td></tr><tr><td style=text-align:center> </td><td style=text-align:left><strong>Concepts in machine learning: supervised and unsupervised learning</strong></td></tr><tr><td style=text-align:center>03.1</td><td style=text-align:left>Principal Component Analysis 1</td></tr><tr><td style=text-align:center>03.2</td><td style=text-align:left>Principal Component Analysis 2</td></tr><tr><td style=text-align:center>05.1</td><td style=text-align:left>Classification with k-nearest neighbors (k-NN) algorithm 1</td></tr><tr><td style=text-align:center>05.2</td><td style=text-align:left>Classification with k-nearest neighbors (k-NN) algorithm 2</td></tr><tr><td style=text-align:center> </td><td style=text-align:left><strong>Artificial neural networks: structure and training</strong></td></tr><tr><td style=text-align:center>06.1</td><td style=text-align:left>Concept of Artificial Neural Network (ANN)</td></tr><tr><td style=text-align:center>06.2</td><td style=text-align:left>Architecture of Multi-Layer Perceptron (MLP) 1</td></tr><tr><td style=text-align:center>07.1</td><td style=text-align:left>Architecture of Multi-Layer Perceptron (MLP) 2</td></tr><tr><td style=text-align:center>07.2</td><td style=text-align:left>ANN basic method hands-on</td></tr><tr><td style=text-align:center>08.1</td><td style=text-align:left>Midterm</td></tr><tr><td style=text-align:center>08.2</td><td style=text-align:left>ANN hierarchy design</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Independent assignment</td></tr></tbody></table></div><h2 id=tentative-plan-sv>tentative plan (sv)</h2><link rel=stylesheet href="/butiran/css/table-0.css?v=1764500267"><div class=table-0><table><thead><tr><th style=text-align:center>Week</th><th style=text-align:left>Topic ↓ Subtopic</th></tr></thead><tbody><tr><td style=text-align:center> </td><td style=text-align:left><strong>Probability distributions and their applications</strong></td></tr><tr><td style=text-align:center>09.1</td><td style=text-align:left>Introduction to probability distributions</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Common probability distributions in Machine Learning</td></tr><tr><td style=text-align:center>09.2</td><td style=text-align:left>Applications in Machine Learning</td></tr><tr><td style=text-align:center> </td><td style=text-align:left><strong>Gaussian process regression for atomic force field modeling</strong></td></tr><tr><td style=text-align:center>10.1</td><td style=text-align:left>Background concepts</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Representing atomic environments</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Model training and prediction</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Force field construction</td></tr><tr><td style=text-align:center>10.2</td><td style=text-align:left>applications</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Software and tools</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Limitations and challenges</td></tr><tr><td style=text-align:center> </td><td style=text-align:left><strong>Genetic algorithms and evolutionary computation</strong></td></tr><tr><td style=text-align:center>11.1</td><td style=text-align:left>Foundations of Evolutionary Computation</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Genetic Algorithms (GAs)</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Evolutionary Strategies (ES)</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Genetic Programming (GP)</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Differential Evolution (DE)</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Other Evolutionary Algorithms</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Hybrid and Memetic Algorithms</td></tr><tr><td style=text-align:center>11.2</td><td style=text-align:left>Theoretical Aspects</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Applications</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Tools and libraries</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Benchmark problems</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Recent advances and research trends</td></tr><tr><td style=text-align:center> </td><td style=text-align:left><strong>Bayesian optimization and its applications</strong></td></tr><tr><td style=text-align:center>12.1</td><td style=text-align:left>Foundations of Bayesian optimization</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Advanced techniques</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Algorithmic implementations</td></tr><tr><td style=text-align:center>12.2</td><td style=text-align:left>Applications</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Applications in Machine Learning</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Applications in Science and Engineering</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Applications in Business and Operations</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Software and tools</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Recent research trends</td></tr><tr><td style=text-align:center> </td><td style=text-align:left><strong>Research-Based Learning (RBL)</strong></td></tr><tr><td style=text-align:center>13.1</td><td style=text-align:left>Topics proposing and discussion</td></tr><tr><td style=text-align:center> </td><td style=text-align:left>Working group creation</td></tr><tr><td style=text-align:center>13.2</td><td style=text-align:left>Short presentasion</td></tr><tr><td style=text-align:center>14.1</td><td style=text-align:left>Progress report presentation 1</td></tr><tr><td style=text-align:center>14.2</td><td style=text-align:left>Progress report presentation 2</td></tr><tr><td style=text-align:center>15.1</td><td style=text-align:left>Progress report presentation 3</td></tr><tr><td style=text-align:center>15.2</td><td style=text-align:left>Progress report presentation 4</td></tr><tr><td style=text-align:center>16.1</td><td style=text-align:left>Final report presentation</td></tr><tr><td style=text-align:center>16.2</td><td style=text-align:left>Publishing final report on Medium, OSF, YouTube</td></tr></tbody></table></div><h2 id=notes>notes</h2><ul><li>Information from SIX are gathered and mixed with lecturers discussion.</li><li>There four references from course syllabus <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>, <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>, where the first two are main references, while the others are additional ones.</li><li>There is an additional reference for information related to probability distributions <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>.</li></ul><h2 id=refs>refs</h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Christopher M. Bishop, &ldquo;Pattern Recognition and Machine Learning&rdquo;, 1st edition, Springer, 2006, url
<a href=https://isbnsearch.org/isbn/9780387310732 target=_blank rel="nofollow noopener noreferrer"><span>https://isbnsearch.org/isbn/9780387310732 <i class="fa fa-external-link" style=font-size:14px></i>
</span></a>2dn86 [20250420].&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>S. Haykin, &ldquo;Neural Networks and Learning Machines&rdquo;, 3rd edition, Pearson Education, 2009, url
<a href=https://isbnsearch.org/isbn/9780131471399 target=_blank rel="nofollow noopener noreferrer"><span>https://isbnsearch.org/isbn/9780131471399 <i class="fa fa-external-link" style=font-size:14px></i>
</span></a>b69e4 [20250420].&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Stuart J. Russell, Peter Norvig, &ldquo;Artificial Intelligence: A Modern Approach&rdquo;, 3rd edition, Pearson Education, 2016, url
<a href=https://isbnsearch.org/isbn/9780136042594 target=_blank rel="nofollow noopener noreferrer"><span>https://isbnsearch.org/isbn/9780136042594 <i class="fa fa-external-link" style=font-size:14px></i>
</span></a>s3keu [20250420].&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>Alberto Artasanchez, Prateek Joshi, &ldquo;Artificial Intelligence with Python: Your complete guide to building intelligent apps using Python 3.x&rdquo;, 2nd edition, Packt Publishing, 2020, url
<a href=https://isbnsearch.org/isbn/9781839219535 target=_blank rel="nofollow noopener noreferrer"><span>https://isbnsearch.org/isbn/9781839219535 <i class="fa fa-external-link" style=font-size:14px></i>
</span></a>eb3p2 [20250420].&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>T. T. Soong, &ldquo;Fundamentals of Probability and Statistics for Engineers&rdquo;, Wiley, 1st edition, 2004, url
<a href=https://isbnsearch.org/isbn/9780470868140 target=_blank rel="nofollow noopener noreferrer"><span>https://isbnsearch.org/isbn/9780470868140 <i class="fa fa-external-link" style=font-size:14px></i>
</span></a>[20250420].&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></div></main><footer><link rel=stylesheet href='/butiran/css/footer.css?v=1764500270'><p>Copyright Sparisoma Viridi 2025<a href=/butiran/h2/ style=cursor:text>.</a>
All rights reserved.
Unless stated otherwise in a note.</p></footer></body></html>